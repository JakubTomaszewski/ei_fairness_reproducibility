{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "from algorithms.algorithms import *\n",
    "from utils.models import *\n",
    "from utils.dataloaders import *\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "dataset = GermanDataset(device=device, sensitive_feature_labels=[\"Age\", \"Sex\"])\n",
    "\n",
    "print(dataset.sensitive_attrs)\n",
    "#print(dataset.XZ_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res():\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'be_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'be_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'be_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    return train, val, test\n",
    "\n",
    "def append_res(l,acc,ei,be,dp,eo,eodd):\n",
    "    l['accuracy'].append(acc)\n",
    "    l['ei_disparity'].append(ei)\n",
    "    l['be_disparity'].append(be)\n",
    "    l['dp_disparity'].append(dp)\n",
    "    l['eo_disparity'].append(eo)\n",
    "    l['eodd_disparity'].append(eodd)\n",
    "\n",
    "def get_res(l):\n",
    "    res = {}\n",
    "    res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "    res['accuracy_var'] = np.std(l['accuracy'])\n",
    "    res['accuracy_list'] = l['accuracy']\n",
    "    res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "    res['ei_var'] = np.std(l['ei_disparity'])\n",
    "    res['ei_list'] = l['ei_disparity']\n",
    "    res['be_mean'] = np.mean(l['be_disparity'])\n",
    "    res['be_var'] = np.std(l['be_disparity'])\n",
    "    res['be_list'] = l['be_disparity']\n",
    "    res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "    res['dp_var'] = np.std(l['dp_disparity'])\n",
    "    res['dp_list'] = l['dp_disparity']\n",
    "    res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "    res['eo_var'] = np.std(l['eo_disparity'])\n",
    "    res['eo_list'] = l['eo_disparity']\n",
    "    res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "    res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "    res['eodd_list'] = l['eodd_disparity']\n",
    "    return res\n",
    "\n",
    "def lr_kde_model_runner(dataset, hp, seeds):\n",
    "    \n",
    "    train, val, test = generate_res()\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_kde_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'], \n",
    "            h=hp['h'], \n",
    "            delta_huber=hp['delta_huber'], \n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_be_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_be,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_be,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fb_model_runner(dataset, hp, seeds):\n",
    "\n",
    "    train, val, test = generate_res()\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fb_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_be_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_be,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_be,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fc_model_runner(dataset, hp, seeds):\n",
    "    \n",
    "    train, val, test = generate_res()\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fc_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_be_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_be,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_be,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, BE_hp_fb, seeds):\n",
    "    \n",
    "    _, _, SGD = lr_kde_model_runner(dataset, SGD_hp, seeds)\n",
    "    _, _, EI_fc = lr_fc_model_runner(dataset, EI_hp_fc, seeds)\n",
    "    _, _, EI_kde = lr_kde_model_runner(dataset, EI_hp_kde, seeds)\n",
    "    _, _, BE_fb = lr_fb_model_runner(dataset, BE_hp_fb, seeds)\n",
    "    _, _, EI_fb = lr_fb_model_runner(dataset, EI_hp_fb, seeds)\n",
    "    \n",
    "    return SGD, EI_fc, EI_kde, EI_fb, BE_fb\n",
    "\n",
    "def fb_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fb_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['be_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'be', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def kde_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_kde_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['be_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'be', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def fc_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fc_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['be_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'be', 'dp', 'eo', 'eodd']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\s1\\fact\\ei_fairness_reproducibility\\notebooks\\..\\utils\\dataloaders.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return torch.FloatTensor(X).to(device), torch.FloatTensor(Y).to(device), torch.FloatTensor(Z).to(device), torch.FloatTensor(XZ).to(device)\n",
      "Training: 100%|██████████| 100/100 [00:04<00:00, 23.95epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 47/100 [00:01<00:01, 48.46epochs/s]"
     ]
    }
   ],
   "source": [
    "SGD_hp_test = {}\n",
    "SGD_hp_test['learning_rate'] = [0.0001, 0.001, 0.01, 0.1]\n",
    "SGD_hp_test['lambda_'] = [0]\n",
    "SGD_hp_test['n_epochs'] = 100\n",
    "SGD_hp_test['batch_size'] = 1024\n",
    "SGD_hp_test['fairness'] = ''\n",
    "SGD_hp_test['h'] = 0.01\n",
    "SGD_hp_test['delta_huber'] = 0.5\n",
    "SGD_hp_test['delta_effort'] = 0.5\n",
    "\n",
    "kde_hyperparameter_test(dataset, SGD_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate is decided as 0.005.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_hp = SGD_hp_test.copy()\n",
    "SGD_hp['learning_rate'] = 0.1\n",
    "SGD_hp['lambda_'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BE Hyperparameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 37.32epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 47.16epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:05<00:00, 17.57epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:04<00:00, 23.27epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 45.48epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val        ei         be        dp         eo      eodd\n",
      "---------------  ---------  ----------------  --------------  --------  ---------  --------  ---------  --------\n",
      "            0.1        0            0.779687         0.75625  0.180392  0.034375   0.209722  0.124956   0.203191\n",
      "            0.1        0.1          0.76875          0.71875  0.375     0.0451389  0.113889  0.0849558  0.180851\n",
      "            0.1        0.2          0.771875         0.71875  0.339286  0.0388889  0.113889  0.0849558  0.180851\n",
      "            0.1        0.3          0.770312         0.73125  0.340659  0.0513889  0.126389  0.102655   0.180851\n",
      "            0.1        0.4          0.770312         0.7375   0.305556  0.0361111  0.120139  0.102655   0.159574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BE_hp_test = SGD_hp_test.copy()\n",
    "BE_hp_test['learning_rate'] = [0.1]\n",
    "BE_hp_test['lambda_'] = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "BE_hp_test['fairness'] = 'BE'\n",
    "\n",
    "fb_hyperparameter_test(dataset, BE_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_hp_fb = BE_hp_test.copy()\n",
    "BE_hp_fb['learning_rate'] = 0.1\n",
    "BE_hp_fb['lambda_'] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### EI Hyperparameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:05<00:00, 18.65epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 44.93epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 34.48epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:05<00:00, 18.42epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 47.49epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:01<00:00, 64.92epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val         ei         be        dp         eo      eodd\n",
      "---------------  ---------  ----------------  --------------  ---------  ---------  --------  ---------  --------\n",
      "            0.1       0             0.779687         0.75625  0.180392   0.034375   0.209722  0.124956   0.203191\n",
      "            0.1       0.2           0.773438         0.74375  0.165865   0.034375   0.177778  0.124956   0.145745\n",
      "            0.1       0.6           0.765625         0.7375   0.0960591  0.0104167  0.129861  0.0938053  0.138298\n",
      "            0.1       0.8           0.746875         0.74375  0.0409091  0.021875   0.213889  0.151858   0.168085\n",
      "            0.1       0.9           0.460938         0.50625  0.0723684  0.05625    0.213889  0.282124   0.282124\n",
      "            0.1       0.95          0.7              0.70625  0          0          0         0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.1]\n",
    "EI_hp_test['lambda_'] = [0, 0.2, 0.6, 0.8, 0.9, 0.95]\n",
    "EI_hp_test['fairness'] = 'EI'\n",
    "\n",
    "kde_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda for EI is decided as 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_kde = EI_hp_test.copy()\n",
    "EI_hp_kde['learning_rate'] = 0.1\n",
    "EI_hp_kde['lambda_'] = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 4/100 [00:40<13:58,  8.73s/epochs]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [01:00<00:00,  1.65epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:05<00:00, 17.19epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:03<00:00, 32.93epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 37.35epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:05<00:00, 19.12epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 34.80epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val        ei         be        dp        eo      eodd\n",
      "---------------  ---------  ----------------  --------------  --------  ---------  --------  --------  --------\n",
      "            0.1       0             0.779687         0.75625  0.180392  0.034375   0.209722  0.124956  0.203191\n",
      "            0.1       0.6           0.779687         0.75     0.161905  0.04375    0.225694  0.156106  0.203191\n",
      "            0.1       0.8           0.779687         0.75     0.161905  0.04375    0.225694  0.156106  0.203191\n",
      "            0.1       0.9           0.779687         0.75     0.161905  0.04375    0.225694  0.156106  0.203191\n",
      "            0.1       0.95          0.779687         0.75     0.190476  0.034375   0.225694  0.156106  0.203191\n",
      "            0.1       0.99          0.775            0.75     0.127273  0.0548611  0.215972  0.164956  0.174468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.1]\n",
    "EI_hp_test['lambda_'] = [0, 0.6, 0.8, 0.9, 0.95, 0.99]\n",
    "EI_hp_test['fairness'] = 'EI'\n",
    "\n",
    "fc_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fc = EI_hp_test.copy()\n",
    "EI_hp_fc['learning_rate'] = 0.1\n",
    "EI_hp_fc['lambda_'] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 42.71epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:04<00:00, 20.70epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:02<00:00, 36.83epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:01<00:00, 50.39epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:01<00:00, 59.35epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val         ei         be        dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ---------  ---------  --------  ---------  ---------\n",
      "            0.1        0            0.779687         0.75625  0.180392   0.034375   0.209722  0.124956   0.203191\n",
      "            0.1        0.1          0.775            0.74375  0.183333   0.0361111  0.168056  0.133805   0.133805\n",
      "            0.1        0.2          0.765625         0.75625  0.0882353  0.0458333  0.143056  0.0849558  0.103191\n",
      "            0.1        0.4          0.746875         0.74375  0.166667   0.0583333  0.109722  0.106903   0.144681\n",
      "            0.1        0.6          0.707812         0.70625  0.0555556  0.01875    0.0125    0.025592   0.0414894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.1]\n",
    "EI_hp_test['lambda_'] = [0, 0.1, 0.2, 0.4, 0.6]\n",
    "EI_hp_test['fairness'] = 'EI'\n",
    "\n",
    "fb_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fb = EI_hp_test.copy()\n",
    "EI_hp_fb['learning_rate'] = 0.1\n",
    "EI_hp_fb['lambda_'] = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5172\\392662720.py:60: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seeds[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 41/100 [00:01<00:02, 22.49epochs/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m seeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m SGD, EI_fc, EI_kde, EI_fb, BE_fb \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSGD_hp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEI_hp_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEI_hp_kde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEI_hp_fb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBE_hp_fb\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 181\u001b[0m, in \u001b[0;36mexperiment_runner\u001b[1;34m(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, BE_hp_fb, seeds)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexperiment_runner\u001b[39m(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, BE_hp_fb, seeds):\n\u001b[1;32m--> 181\u001b[0m     _, _, SGD \u001b[38;5;241m=\u001b[39m \u001b[43mlr_kde_model_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSGD_hp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     _, _, EI_fc \u001b[38;5;241m=\u001b[39m lr_fc_model_runner(dataset, EI_hp_fc, seeds)\n\u001b[0;32m    183\u001b[0m     _, _, EI_kde \u001b[38;5;241m=\u001b[39m lr_kde_model_runner(dataset, EI_hp_kde, seeds)\n",
      "Cell \u001b[1;32mIn[4], line 70\u001b[0m, in \u001b[0;36mlr_kde_model_runner\u001b[1;34m(dataset, hp, seeds)\u001b[0m\n\u001b[0;32m     67\u001b[0m lr \u001b[38;5;241m=\u001b[39m hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     68\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer_kde_fair\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_blind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfairness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfairness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambda_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelta_huber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelta_huber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimal_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelta_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdelta_effort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m append_res(train,results\u001b[38;5;241m.\u001b[39mtrain_acc_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],results\u001b[38;5;241m.\u001b[39mtrain_ei_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],results\u001b[38;5;241m.\u001b[39mtrain_be_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],results\u001b[38;5;241m.\u001b[39mtrain_dp_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],results\u001b[38;5;241m.\u001b[39mtrain_eo_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],results\u001b[38;5;241m.\u001b[39mtrain_eodd_hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     87\u001b[0m append_res(val,results\u001b[38;5;241m.\u001b[39mval_acc,results\u001b[38;5;241m.\u001b[39mval_ei,results\u001b[38;5;241m.\u001b[39mval_be,results\u001b[38;5;241m.\u001b[39mval_dp,results\u001b[38;5;241m.\u001b[39mval_eo,results\u001b[38;5;241m.\u001b[39mval_eodd)\n",
      "File \u001b[1;32mc:\\Users\\User\\s1\\fact\\ei_fairness_reproducibility\\notebooks\\..\\algorithms\\algorithms_jakub.py:149\u001b[0m, in \u001b[0;36mtrainer_kde_fair\u001b[1;34m(model, dataset, optimizer, device, n_epochs, batch_size, z_blind, fairness, lambda_, h, delta_huber, optimal_effort, delta_effort, effort_iter, effort_lr, effort_norm)\u001b[0m\n\u001b[0;32m    147\u001b[0m Yhat_train \u001b[38;5;241m=\u001b[39m model(train_dataset\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mX[train_dataset\u001b[38;5;241m.\u001b[39mindices])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimal_effort \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     Yhat_max_train \u001b[38;5;241m=\u001b[39m \u001b[43mOptimal_effort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_effort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffort_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     Yhat_max_train \u001b[38;5;241m=\u001b[39m PGD_effort(model, dataset, train_dataset\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mX[train_dataset\u001b[38;5;241m.\u001b[39mindices], effort_iter, effort_lr, delta_effort, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\User\\s1\\fact\\ei_fairness_reproducibility\\notebooks\\..\\utils\\effort.py:56\u001b[0m, in \u001b[0;36mOptimal_effort\u001b[1;34m(model, dataset, x, delta, norm, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m         weights \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdetach() \n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 56\u001b[0m     efforts_update \u001b[38;5;241m=\u001b[39m delta \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(weights) \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     efforts_update[:,improvable_indices] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(efforts_update[:,improvable_indices], \u001b[38;5;241m-\u001b[39mdelta, delta)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# elif norm=='l2':\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds = np.arange(1,6)\n",
    "\n",
    "SGD, EI_fc, EI_kde, EI_fb, BE_fb = experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, BE_hp_fb ,seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model      accuracy_mean    accuracy_var    ei_mean      ei_var    be_mean     be_var    dp_mean      dp_var    eo_mean      eo_var    eodd_mean    eodd_var\n",
      "-------  ---------------  --------------  ---------  ----------  ---------  ---------  ---------  ----------  ---------  ----------  -----------  ----------\n",
      "SGD                0.776      0.00583095  0.033636   0.00455034  0.105818   0.0190896  0.107227   0.0190269   0.109463   0.0151374     0.128242    0.0267759\n",
      "EI FC              0.786      0.0152971   0.0633268  0.0281924   0.0747609  0.0141063  0.0682884  0.008949    0.0799483  0.0234947     0.083551    0.0166657\n",
      "EI KDE             0.722      0.0218174   0.0620284  0.0231114   0.0739394  0.0290602  0.0721358  0.0310583   0.0912719  0.0380076     0.0936493   0.0344409\n",
      "EI FB              0.784      0.0115758   0.0291196  0.0138806   0.0642884  0.0082529  0.0631504  0.0107851   0.0799483  0.0109684     0.0799483   0.0109684\n",
      "BE FB              0.786      0.00969536  0.0415201  0.00773254  0.0259338  0.0113565  0.0232177  0.00591232  0.040324   0.00888534    0.0925025   0.0476193\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "models = [\"SGD\", \"EI FC\", \"EI KDE\", \"EI FB\", \"BE FB\"]\n",
    "sol = [SGD, EI_fc, EI_kde, EI_fb, BE_fb]\n",
    "for i in range(len(models)):\n",
    "    c = []\n",
    "    c.append(models[i])\n",
    "    res = sol[i]\n",
    "    c.append(res['accuracy_mean'])\n",
    "    c.append(res['accuracy_var'])\n",
    "    c.append(res['ei_mean'])\n",
    "    c.append(res['ei_var'])\n",
    "    c.append(res['be_mean'])\n",
    "    c.append(res['be_var'])\n",
    "    c.append(res['dp_mean'])\n",
    "    c.append(res['dp_var'])\n",
    "    c.append(res['eo_mean'])\n",
    "    c.append(res['eo_var'])\n",
    "    c.append(res['eodd_mean'])\n",
    "    c.append(res['eodd_var'])\n",
    "    result.append(c)\n",
    "\n",
    "print(tabulate(result, headers=[\"model\",\"accuracy_mean\",\"accuracy_var\",\"ei_mean\",\"ei_var\",\"be_mean\",\"be_var\", \"dp_mean\", \"dp_var\",\"eo_mean\",\"eo_var\",\"eodd_mean\",\"eodd_var\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sampler_fairness')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902159ac64d6098f1cb3487d51e5a4224d4aca1118329737e4cb7cda9bc70f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
