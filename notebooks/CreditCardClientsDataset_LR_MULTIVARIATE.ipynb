{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "from algorithms.algorithms import *\n",
    "from utils.models import *\n",
    "from utils.dataloaders import *\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "np.random.seed(0)\n",
    "\n",
    "dataset = CreditCardClientsDataset(device=device, sensitive_feature_labels=[\"SEX\", \"AGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_kde_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_kde_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'], \n",
    "            h=hp['h'], \n",
    "            delta_huber=hp['delta_huber'], \n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fb_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fb_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fc_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fc_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, seeds):\n",
    "    \n",
    "    _, _, SGD = lr_kde_model_runner(dataset, SGD_hp, seeds)\n",
    "    _, _, EI_fc = lr_fc_model_runner(dataset, EI_hp_fc, seeds)\n",
    "    _, _, EI_kde = lr_kde_model_runner(dataset, EI_hp_kde, seeds)\n",
    "    _, _, EI_fb = lr_fb_model_runner(dataset, EI_hp_fb, seeds)\n",
    "    \n",
    "    return SGD, EI_fc, EI_kde, EI_fb\n",
    "\n",
    "def fb_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fb_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def kde_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_kde_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def fc_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fc_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_hp_test = {}\n",
    "SGD_hp_test['learning_rate'] = [0.0001, 0.001, 0.01, 0.1]\n",
    "SGD_hp_test['lambda_'] = [0]\n",
    "SGD_hp_test['n_epochs'] = 100\n",
    "SGD_hp_test['batch_size'] = 1024 \n",
    "SGD_hp_test['fairness'] = ''\n",
    "SGD_hp_test['h'] = 0.01\n",
    "SGD_hp_test['delta_huber'] = 0.5\n",
    "SGD_hp_test['delta_effort'] = 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.46epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.50epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.55epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.66epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val         ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ---------  ---------  ---------  ---------\n",
      "         0.0001          0          0.801058        0.798307  0.0283603  0.0150492  0.036735   0.036735\n",
      "         0.001           0          0.814497        0.814603  0.0136013  0.0309424  0.0683472  0.0683472\n",
      "         0.01            0          0.817302        0.816085  0.0075992  0.0227132  0.04639    0.04639\n",
      "         0.1             0          0.81836         0.818624  0.0171846  0.0242504  0.0497741  0.0497741\n"
     ]
    }
   ],
   "source": [
    "kde_hyperparameter_test(dataset, SGD_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_hp = SGD_hp_test.copy()\n",
    "SGD_hp['learning_rate'] = 0.01\n",
    "SGD_hp['lambda_'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.01]\n",
    "EI_hp_test['lambda_'] = [0, 0.2, 0.6, 0.8, 0.9]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:31<00:00,  3.19epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:28<00:00,  3.48epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:29<00:00,  3.41epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:29<00:00,  3.36epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:29<00:00,  3.39epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val          ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ----------  ---------  ---------  ---------\n",
      "           0.01        0            0.817302        0.816085  0.0075992   0.0227132  0.04639    0.04639\n",
      "           0.01        0.2          0.817354        0.815873  0.00497947  0.0223926  0.0473352  0.0473352\n",
      "           0.01        0.6          0.817196        0.81672   0.00453257  0.0224305  0.0482804  0.0482804\n",
      "           0.01        0.8          0.816455        0.815661  0.00281881  0.0216503  0.0487225  0.0487225\n",
      "           0.01        0.9          0.814974        0.813333  0.0105269   0.0392893  0.081888   0.081888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kde_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_kde = EI_hp_test.copy()\n",
    "EI_hp_kde['learning_rate'] = 0.01\n",
    "EI_hp_kde['lambda_'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.01]\n",
    "EI_hp_test['lambda_'] = [0, 0.6, 0.8, 0.9, 0.95]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.47epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.64epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.68epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.42epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.75epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val          ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ----------  ---------  ---------  ---------\n",
      "           0.01       0             0.817302        0.816085  0.0075992   0.0227132  0.04639    0.04639\n",
      "           0.01       0.6           0.817407        0.816296  0.00560335  0.0217515  0.0473352  0.0473352\n",
      "           0.01       0.8           0.816984        0.81672   0.00663469  0.0215337  0.0475754  0.0475754\n",
      "           0.01       0.9           0.816349        0.816296  0.00830017  0.0205195  0.0514107  0.0514107\n",
      "           0.01       0.95          0.815767        0.816296  0.00430367  0.0192697  0.049815   0.049815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fc_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fc = EI_hp_test.copy()\n",
    "EI_hp_fc['learning_rate'] = 0.01\n",
    "EI_hp_fc['lambda_'] = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.01]\n",
    "EI_hp_test['lambda_'] = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:28<00:00,  3.48epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.66epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.70epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.64epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:30<00:00,  3.23epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val           ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  -----------  ---------  ---------  ---------\n",
      "           0.01        0            0.817302        0.816085  0.0075992    0.0227132  0.04639    0.04639\n",
      "           0.01        0.2          0.818466        0.818413  0.00146378   0.0210355  0.0504655  0.0504655\n",
      "           0.01        0.4          0.817989        0.818413  0.0126329    0.0184246  0.0395654  0.0395654\n",
      "           0.01        0.6          0.817884        0.81672   0.0148132    0.0196945  0.0375956  0.0375956\n",
      "           0.01        0.8          0.808307        0.805926  0.000942176  0.0221216  0.0354855  0.0354855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fb_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fb = EI_hp_test.copy()\n",
    "EI_hp_fb['learning_rate'] = 0.01\n",
    "EI_hp_fb['lambda_'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/grmv219n3mzbyfj882m03j3c0000gn/T/ipykernel_3479/3561611485.py:29: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seeds[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epochs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:23<00:00,  4.34epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.48epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.55epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:22<00:00,  4.51epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:21<00:00,  4.59epochs/s]\n",
      "/var/folders/_1/grmv219n3mzbyfj882m03j3c0000gn/T/ipykernel_3479/3561611485.py:195: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seeds[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:25<00:00,  3.94epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:24<00:00,  4.00epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:25<00:00,  3.91epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:26<00:00,  3.83epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:25<00:00,  3.85epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:31<00:00,  3.13epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:32<00:00,  3.10epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:31<00:00,  3.13epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:32<00:00,  3.10epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:31<00:00,  3.14epochs/s]\n",
      "/var/folders/_1/grmv219n3mzbyfj882m03j3c0000gn/T/ipykernel_3479/3561611485.py:113: DeprecationWarning: Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n",
      "  random.seed(seeds[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.62epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.61epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.60epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.67epochs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [00:27<00:00,  3.63epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = np.arange(1,6)\n",
    "\n",
    "SGD, EI_fc, EI_kde, EI_fb = experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model      accuracy_mean    accuracy_var     ei_mean       ei_var    dp_mean       dp_var    eo_mean      eo_var    eodd_mean    eodd_var\n",
      "-------  ---------------  --------------  ----------  -----------  ---------  -----------  ---------  ----------  -----------  ----------\n",
      "SGD             0.825597     0.000590337  0.0133685   0.00185294   0.0204723  0.000718165  0.0261748  0.00162436    0.0261748  0.00162436\n",
      "EI FC           0.823328     0.00076162   0.00334426  0.00101703   0.0168162  0.000819615  0.016367   0.00204342    0.016367   0.00204342\n",
      "EI KDE          0.824953     0.000710214  0.00283053  0.000363106  0.0180179  0.00115796   0.020215   0.00307935    0.020215   0.00307935\n",
      "EI FB           0.809142     0.00293337   0.00328821  0.00154129   0.0122883  0.00290608   0.0225487  0.010165      0.024597   0.00688776\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "models = [\"SGD\", \"EI FC\", \"EI KDE\", \"EI FB\"]\n",
    "sol = [SGD, EI_fc, EI_kde, EI_fb]\n",
    "for i in range(len(models)):\n",
    "    c = []\n",
    "    c.append(models[i])\n",
    "    res = sol[i]\n",
    "    c.append(res['accuracy_mean'])\n",
    "    c.append(res['accuracy_var'])\n",
    "    c.append(res['ei_mean'])\n",
    "    c.append(res['ei_var'])\n",
    "    c.append(res['dp_mean'])\n",
    "    c.append(res['dp_var'])\n",
    "    c.append(res['eo_mean'])\n",
    "    c.append(res['eo_var'])\n",
    "    c.append(res['eodd_mean'])\n",
    "    c.append(res['eodd_var'])\n",
    "    result.append(c)\n",
    "\n",
    "print(tabulate(result, headers=[\"model\",\"accuracy_mean\",\"accuracy_var\",\"ei_mean\",\"ei_var\", \"dp_mean\", \"dp_var\",\"eo_mean\",\"eo_var\",\"eodd_mean\",\"eodd_var\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sampler_fairness')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902159ac64d6098f1cb3487d51e5a4224d4aca1118329737e4cb7cda9bc70f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
