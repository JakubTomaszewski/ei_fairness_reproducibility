{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "from algorithms.algorithms import *\n",
    "from utils.models import *\n",
    "from utils.dataloaders import *\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "np.random.seed(0)\n",
    "\n",
    "dataset = IncomeDataset(device=device, sensitive_feature_labels=[\"SEX\", \"AGEP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_kde_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_kde_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'], \n",
    "            h=hp['h'], \n",
    "            delta_huber=hp['delta_huber'], \n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fb_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fb_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def lr_fc_model_runner(dataset, hp, seeds):\n",
    "    test = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    train = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "    \n",
    "    val = {'accuracy':[],\n",
    "            'ei_disparity':[],\n",
    "            'dp_disparity':[],\n",
    "            'eo_disparity':[],\n",
    "            'eodd_disparity':[]}\n",
    "\n",
    "    def append_res(l,acc,ei,dp,eo,eodd):\n",
    "        l['accuracy'].append(acc)\n",
    "        l['ei_disparity'].append(ei)\n",
    "        l['dp_disparity'].append(dp)\n",
    "        l['eo_disparity'].append(eo)\n",
    "        l['eodd_disparity'].append(eodd)\n",
    "\n",
    "    for i in range(len(seeds)):\n",
    "        print('training seed', seeds[i] ,'started')\n",
    "        random.seed(seeds[i])\n",
    "        np.random.seed(seeds[i])\n",
    "        torch.manual_seed(seeds[i]) \n",
    "\n",
    "        model = logReg(num_features=dataset.XZ_train.shape[1])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        lr = hp['learning_rate']\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        \n",
    "        results = trainer_fc_fair(\n",
    "            model,\n",
    "            dataset,\n",
    "            optimizer,\n",
    "            device,\n",
    "            n_epochs=hp['n_epochs'],\n",
    "            batch_size=hp['batch_size'], \n",
    "            z_blind=False,\n",
    "            fairness=hp['fairness'], \n",
    "            lambda_=hp['lambda_'],\n",
    "            optimal_effort=True, \n",
    "            delta_effort=hp['delta_effort']\n",
    "            )\n",
    "        \n",
    "        append_res(train,results.train_acc_hist[-1],results.train_ei_hist[-1],results.train_dp_hist[-1],results.train_eo_hist[-1],results.train_eodd_hist[-1])\n",
    "        append_res(val,results.val_acc,results.val_ei,results.val_dp,results.val_eo,results.val_eodd)\n",
    "        append_res(test,results.test_acc,results.test_ei,results.test_dp,results.test_eo,results.test_eodd)\n",
    "\n",
    "    def get_res(l):\n",
    "        res = {}\n",
    "        res['accuracy_mean'] = np.mean(l['accuracy'])\n",
    "        res['accuracy_var'] = np.std(l['accuracy'])\n",
    "        res['accuracy_list'] = l['accuracy']\n",
    "        res['ei_mean'] = np.mean(l['ei_disparity'])\n",
    "        res['ei_var'] = np.std(l['ei_disparity'])\n",
    "        res['ei_list'] = l['ei_disparity']\n",
    "        res['dp_mean'] = np.mean(l['dp_disparity'])\n",
    "        res['dp_var'] = np.std(l['dp_disparity'])\n",
    "        res['dp_list'] = l['dp_disparity']\n",
    "        res['eo_mean'] = np.mean(l['eo_disparity'])\n",
    "        res['eo_var'] = np.std(l['eo_disparity'])\n",
    "        res['eo_list'] = l['eo_disparity']\n",
    "        res['eodd_mean'] = np.mean(l['eodd_disparity'])\n",
    "        res['eodd_var'] = np.std(l['eodd_disparity'])\n",
    "        res['eodd_list'] = l['eodd_disparity']\n",
    "        return res\n",
    "\n",
    "    res_train = get_res(train)\n",
    "    res_val = get_res(val)\n",
    "    res_test = get_res(test)\n",
    "    print('Training finished for all seeds.')\n",
    "    \n",
    "    return res_train, res_val, res_test\n",
    "\n",
    "def experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, seeds):\n",
    "    \n",
    "    _, _, SGD = lr_kde_model_runner(dataset, SGD_hp, seeds)\n",
    "    _, _, EI_fc = lr_fc_model_runner(dataset, EI_hp_fc, seeds)\n",
    "    _, _, EI_kde = lr_kde_model_runner(dataset, EI_hp_kde, seeds)\n",
    "    _, _, EI_fb = lr_fb_model_runner(dataset, EI_hp_fb, seeds)\n",
    "    \n",
    "    return SGD, EI_fc, EI_kde, EI_fb\n",
    "\n",
    "def fb_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fb_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def kde_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_kde_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))\n",
    "\n",
    "def fc_hyperparameter_test(dataset, hp_test, seed=0):\n",
    "    hp = hp_test.copy()\n",
    "    result = []\n",
    "    for i in hp_test['learning_rate']:\n",
    "        for k in hp_test['lambda_']:\n",
    "            c = []\n",
    "            hp['learning_rate'] = i\n",
    "            hp['lambda_'] = k\n",
    "            train, val, _ = lr_fc_model_runner(dataset, hp, seeds=[seed])\n",
    "            c.append(hp['learning_rate'])\n",
    "            c.append(hp['lambda_'])\n",
    "            c.append(train['accuracy_mean'])\n",
    "            c.append(val['accuracy_mean'])\n",
    "            c.append(val['ei_mean'])\n",
    "            c.append(val['dp_mean'])\n",
    "            c.append(val['eo_mean'])\n",
    "            c.append(val['eodd_mean'])\n",
    "            result.append(c)\n",
    "    print(tabulate(result, headers=['learning_rate', 'lambda_', 'accuracy_train', 'accuracy_val','ei', 'dp', 'eo', 'eodd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_hp_test = {}\n",
    "SGD_hp_test['learning_rate'] = [0.0001, 0.001, 0.01, 0.1]\n",
    "SGD_hp_test['lambda_'] = [0]\n",
    "SGD_hp_test['n_epochs'] = 100\n",
    "SGD_hp_test['batch_size'] = 1024 \n",
    "SGD_hp_test['fairness'] = ''\n",
    "SGD_hp_test['h'] = 0.01\n",
    "SGD_hp_test['delta_huber'] = 0.5\n",
    "SGD_hp_test['delta_effort'] = 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [04:32<00:00,  2.72s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [04:28<00:00,  2.69s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [04:24<00:00,  2.65s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [04:15<00:00,  2.56s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val         ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ---------  ---------  ---------  ---------\n",
      "         0.0001          0          0.809016        0.805251  0.0390082  0.0884896  0.0735764  0.0735764\n",
      "         0.001           0          0.819509        0.81378   0.0279595  0.0736958  0.0450344  0.0450344\n",
      "         0.01            0          0.820084        0.813205  0.0317033  0.0715164  0.0459067  0.0459067\n",
      "         0.1             0          0.817968        0.809052  0.0303017  0.0688737  0.0389086  0.0389086\n"
     ]
    }
   ],
   "source": [
    "kde_hyperparameter_test(dataset, SGD_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_hp = SGD_hp_test.copy()\n",
    "SGD_hp['learning_rate'] = 0.001\n",
    "SGD_hp['lambda_'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.001]\n",
    "EI_hp_test['lambda_'] = [0, 0.2, 0.6, 0.8, 0.9]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:16<00:00,  3.16s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:18<00:00,  3.18s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:18<00:00,  3.19s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:15<00:00,  3.15s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:34<00:00,  3.35s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val          ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ----------  ---------  ---------  ---------\n",
      "          0.001        0            0.819509        0.81378   0.0279595   0.0736958  0.0450344  0.0450344\n",
      "          0.001        0.2          0.819094        0.813077  0.0255185   0.0710283  0.0407315  0.0407315\n",
      "          0.001        0.6          0.817249        0.811927  0.0163556   0.0647755  0.0356509  0.0356509\n",
      "          0.001        0.8          0.814007        0.809723  0.0103842   0.0625596  0.0346176  0.0346176\n",
      "          0.001        0.9          0.807666        0.803846  0.00432221  0.0546846  0.0248709  0.0248709\n"
     ]
    }
   ],
   "source": [
    "kde_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_kde = EI_hp_test.copy()\n",
    "EI_hp_kde['learning_rate'] = 0.001\n",
    "EI_hp_kde['lambda_'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.001]\n",
    "EI_hp_test['lambda_'] = [0, 0.6, 0.8, 0.9, 0.95]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:14<00:00,  3.15s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:36<00:00,  3.36s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:10<00:00,  3.10s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [05:00<00:00,  3.01s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "training seed 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [04:56<00:00,  2.97s/epochs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for all seeds.\n",
      "  learning_rate    lambda_    accuracy_train    accuracy_val          ei         dp         eo       eodd\n",
      "---------------  ---------  ----------------  --------------  ----------  ---------  ---------  ---------\n",
      "          0.001       0             0.819509        0.81378   0.0279595   0.0736958  0.0450344  0.0450344\n",
      "          0.001       0.6           0.81685         0.812023  0.023425    0.0735395  0.045628   0.045628\n",
      "          0.001       0.8           0.81356         0.808765  0.0176772   0.072694   0.0459416  0.0459416\n",
      "          0.001       0.9           0.809104        0.8049    0.0126536   0.0705583  0.0444225  0.0444225\n",
      "          0.001       0.95          0.801645        0.798991  0.00865127  0.0681263  0.0435067  0.0435067\n"
     ]
    }
   ],
   "source": [
    "fc_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fc = EI_hp_test.copy()\n",
    "EI_hp_fc['learning_rate'] = 0.001\n",
    "EI_hp_fc['lambda_'] = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_test = SGD_hp_test.copy()\n",
    "EI_hp_test['learning_rate'] = [0.001]\n",
    "EI_hp_test['lambda_'] = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "EI_hp_test['fairness'] = 'EI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_hyperparameter_test(dataset, EI_hp_test, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_hp_fb = EI_hp_test.copy()\n",
    "EI_hp_fb['learning_rate'] = 0.001\n",
    "EI_hp_fb['lambda_'] = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(1,6)\n",
    "\n",
    "SGD, EI_fc, EI_kde, EI_fb = experiment_runner(dataset, SGD_hp, EI_hp_fc, EI_hp_kde, EI_hp_fb, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model      accuracy_mean    accuracy_var     ei_mean       ei_var    dp_mean       dp_var    eo_mean      eo_var    eodd_mean    eodd_var\n",
      "-------  ---------------  --------------  ----------  -----------  ---------  -----------  ---------  ----------  -----------  ----------\n",
      "SGD             0.815736     0.000202763  0.0314628   0.000646209  0.0753856  0.000931734  0.0548995  0.0020109     0.0548995  0.0020109\n",
      "EI FC           0.800296     0.000203791  0.00828454  0.000554726  0.0701167  0.0012244    0.0497843  0.00268926    0.0497843  0.00268926\n",
      "EI KDE          0.804027     0.000490208  0.00541139  0.000779892  0.0441866  0.00401724   0.010895   0.00623057    0.010895   0.00623057\n",
      "EI FB           0.805699     0.000350601  0.00586265  0.00157542   0.0537166  0.00192059   0.0298055  0.00360719    0.0298055  0.00360719\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "models = [\"SGD\", \"EI FC\", \"EI KDE\", \"EI FB\"]\n",
    "sol = [SGD, EI_fc, EI_kde, EI_fb]\n",
    "for i in range(len(models)):\n",
    "    c = []\n",
    "    c.append(models[i])\n",
    "    res = sol[i]\n",
    "    c.append(res['accuracy_mean'])\n",
    "    c.append(res['accuracy_var'])\n",
    "    c.append(res['ei_mean'])\n",
    "    c.append(res['ei_var'])\n",
    "    c.append(res['dp_mean'])\n",
    "    c.append(res['dp_var'])\n",
    "    c.append(res['eo_mean'])\n",
    "    c.append(res['eo_var'])\n",
    "    c.append(res['eodd_mean'])\n",
    "    c.append(res['eodd_var'])\n",
    "    result.append(c)\n",
    "\n",
    "print(tabulate(result, headers=[\"model\",\"accuracy_mean\",\"accuracy_var\",\"ei_mean\",\"ei_var\", \"dp_mean\", \"dp_var\",\"eo_mean\",\"eo_var\",\"eodd_mean\",\"eodd_var\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sampler_fairness')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902159ac64d6098f1cb3487d51e5a4224d4aca1118329737e4cb7cda9bc70f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
